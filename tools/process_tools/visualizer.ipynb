{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizer Raw Data or Pre-Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pcdet.datasets.kitti.kitti_dataset import *\n",
    "from pcdet.datasets.dataset import *\n",
    "from pcdet.datasets import DatasetTemplate\n",
    "from pcdet.utils import common_utils, calibration_kitti, box_utils\n",
    "\n",
    "import yaml\n",
    "from easydict import EasyDict\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "from tools.visual_utils import open3d_vis_utils as Visualizer\n",
    "\n",
    "dataset_cfg=EasyDict(yaml.safe_load(open('/home/rlab10/OpenPCDet/tools/cfgs/dataset_configs/kitti_dataset.yaml')))\n",
    "class_names=['Car', 'Pedestrian', 'Cyclist']\n",
    "file_path = '/home/rlab10/OpenPCDet/pcdet/datasets/kitti/kitti_dataset.py' \n",
    "# /home/rlab10/OpenPCDet\n",
    "ROOT_DIR = (Path(file_path).resolve().parent / '../../../').resolve()\n",
    "data_path = ROOT_DIR / 'data' / 'kitti'\n",
    "ext = '.bin'\n",
    "data = []\n",
    "num_features = len(dataset_cfg.POINT_FEATURE_ENCODING.src_feature_list)\n",
    "\n",
    "class DemoDataset(DatasetTemplate):\n",
    "    def __init__(self, dataset_cfg, class_names, training=True, root_path=None, logger=None, data_processor_flag=False, fov_mode=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_path:\n",
    "            dataset_cfg:\n",
    "            class_names:\n",
    "            training:\n",
    "            logger:\n",
    "        \"\"\"\n",
    "        super().__init__(\n",
    "            dataset_cfg=dataset_cfg, class_names=class_names, training=training, root_path=root_path, logger=logger\n",
    "        )\n",
    "        self.split = self.dataset_cfg.DATA_SPLIT['train']\n",
    "        self.root_split_path = self.root_path / ('training' if self.split != 'test' else 'testing')\n",
    "        split_dir = self.root_path / 'ImageSets' / (self.split + '.txt')\n",
    "        self.sample_id_list = [x.strip() for x in open(split_dir).readlines()] if split_dir.exists() else None\n",
    "        self.demo_infos = []\n",
    "        self.include_kitti_data(mode='train')\n",
    "        self.data_processor_flag = data_processor_flag\n",
    "        self.fov_mode = fov_mode\n",
    "\n",
    "    def include_kitti_data(self, mode):\n",
    "        if self.logger is not None:\n",
    "            self.logger.info('DemoDataset: Loading raw KITTI dataset')\n",
    "        demo_infos = []\n",
    "\n",
    "        for info_path in self.dataset_cfg.INFO_PATH[mode]: # 'train', bc training=True\n",
    "            info_path = self.root_path / info_path\n",
    "            if not info_path.exists():\n",
    "                continue\n",
    "            # Read the data infos from kitti_infos_train.pkl\n",
    "            with open(info_path, 'rb') as f:\n",
    "                infos = pickle.load(f)\n",
    "                demo_infos.extend(infos)\n",
    "        # Add the newly loaded KITTI dataset information to kitti_infos list.\n",
    "        self.demo_infos.extend(demo_infos)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sample_id_list)\n",
    "    \n",
    "    def get_lidar(self, idx):\n",
    "        lidar_file = self.root_split_path / 'velodyne' / ('%s.bin' % idx)\n",
    "        assert lidar_file.exists()\n",
    "        return np.fromfile(str(lidar_file), dtype=np.float32).reshape(-1, 4)\n",
    "\n",
    "    def get_calib(self, idx):\n",
    "        calib_file = self.root_split_path / 'calib' / ('%s.txt' % idx)\n",
    "        assert calib_file.exists()\n",
    "        return calibration_kitti.Calibration(calib_file)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_fov_flag(pts_rect, img_shape, calib):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            pts_rect:\n",
    "            img_shape:\n",
    "            calib:\n",
    "\n",
    "        Returns:\n",
    "\n",
    "        \"\"\"\n",
    "        pts_img, pts_rect_depth = calib.rect_to_img(pts_rect)\n",
    "        val_flag_1 = np.logical_and(pts_img[:, 0] >= 0, pts_img[:, 0] < img_shape[1])\n",
    "        val_flag_2 = np.logical_and(pts_img[:, 1] >= 0, pts_img[:, 1] < img_shape[0])\n",
    "        val_flag_merge = np.logical_and(val_flag_1, val_flag_2)\n",
    "        pts_valid_flag = np.logical_and(val_flag_merge, pts_rect_depth >= 0)\n",
    "\n",
    "        return pts_valid_flag\n",
    "\n",
    "    def prepare_demo_data(self, data_dict):\n",
    "        print('DemoDataset: prepare_demo_data() called')\n",
    "        if 'gt_boxes' not in data_dict:\n",
    "            assert 'gt_boxes' in data_dict, 'gt_boxes should be provided for demo visualization'\n",
    "        else:         \n",
    "            if data_dict.get('gt_boxes', None) is not None:\n",
    "                selected = common_utils.keep_arrays_by_name(data_dict['gt_names'], self.class_names)\n",
    "                data_dict['gt_boxes'] = data_dict['gt_boxes'][selected]\n",
    "                data_dict['gt_names'] = data_dict['gt_names'][selected]\n",
    "                gt_classes = np.array([self.class_names.index(n) + 1 for n in data_dict['gt_names']], dtype=np.int32)\n",
    "                # already transformed 3D boxes LiDAR coord. + add number for the class\n",
    "                gt_boxes = np.concatenate((data_dict['gt_boxes'], gt_classes.reshape(-1, 1).astype(np.float32)), axis=1)\n",
    "                data_dict['gt_boxes'] = gt_boxes\n",
    "\n",
    "\n",
    "            if data_dict.get('points', None) is not None:\n",
    "                data_dict = self.point_feature_encoder.forward(data_dict)\n",
    "            \n",
    "            if self.data_processor_flag:\n",
    "                print('DemoDataset: data processing activated')\n",
    "                data_dict = self.data_processor.forward(data_dict=data_dict)\n",
    "    \n",
    "        return data_dict\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        print('DemoDataset: __getitem__ called')\n",
    "        if self.merge_all_iters_to_one_epoch:\n",
    "            index = index % len(self.demo_infos)\n",
    "        # works\n",
    "        info = copy.deepcopy(self.demo_infos[index])\n",
    "\n",
    "        sample_idx = info['point_cloud']['lidar_idx']\n",
    "        img_shape = info['image']['image_shape']\n",
    "        calib = self.get_calib(sample_idx)\n",
    "        get_item_list = self.dataset_cfg.get('GET_ITEM_LIST', ['points'])\n",
    "\n",
    "        input_dict = {\n",
    "            'frame_id': sample_idx,\n",
    "        }\n",
    "\n",
    "        if 'annos' in info:\n",
    "            annos = info['annos']\n",
    "            annos = common_utils.drop_info_with_name(annos, name = 'DontCare')\n",
    "            loc, dims, rots = annos['location'], annos['dimensions'], annos['rotation_y']\n",
    "            gt_names = annos['name']\n",
    "            gt_boxes_camera = np.concatenate([loc, dims, rots[...,np.newaxis]], axis = 1).astype(np.float32)\n",
    "            gt_boxes_lidar = box_utils.boxes3d_kitti_camera_to_lidar(gt_boxes_camera, calib)\n",
    "\n",
    "        input_dict.update({\n",
    "            'gt_names': gt_names,\n",
    "            'gt_boxes': gt_boxes_lidar\n",
    "        })\n",
    "\n",
    "        if 'points' in get_item_list:\n",
    "            points = self.get_lidar(sample_idx)\n",
    "\n",
    "            if self.fov_mode:\n",
    "                if self.dataset_cfg.FOV_POINTS_ONLY:\n",
    "                    print('DemoDataset: fov mode activated')\n",
    "                    # only the points in the FOV of the camera are important for me\n",
    "                    pts_rect = calib.lidar_to_rect(points[:, 0:3])\n",
    "                    fov_flag = self.get_fov_flag(pts_rect, img_shape, calib)\n",
    "                    points = points[fov_flag]\n",
    "            input_dict['points'] = points\n",
    "\n",
    "        data_dict = self.prepare_demo_data(data_dict=input_dict)\n",
    "\n",
    "        return data_dict\n",
    "\n",
    "def main(mode=str):\n",
    "    logger = common_utils.create_logger()\n",
    "    if mode == 'raw':\n",
    "        logger.info('-----------------Quick Visualizer Demo of raw data-------------------------')\n",
    "        logger.info(f'Mode for visualization: {mode}')\n",
    "        demo_dataset = DemoDataset(dataset_cfg=dataset_cfg, class_names=class_names, training=False, root_path=data_path, logger=logger, data_processor_flag=False, fov_mode=False)\n",
    "        logger.info(f'Total number of samples: \\t{len(demo_dataset)}')\n",
    "        # raw data not  0-4\n",
    "        #demo_dataset.demo_infos[4]\n",
    "        #demo_dataset[0]\n",
    "        # get_infos oder prepare_data hier implementieren(flow: include_kitti_data->__getitem__->prepare_data)\n",
    "        # or using KittiDataset for accessing the\n",
    "        data_dict = demo_dataset[0]\n",
    "        print('frame_id: ', data_dict['frame_id'])\n",
    "        points = data_dict['points']\n",
    "        gt_boxes = data_dict['gt_boxes']\n",
    "\n",
    "        Visualizer.draw_demo_scenes(points=points, gt_boxes=gt_boxes, point_colors=None, draw_origin=True)\n",
    "        logger.info('Demo visualization of raw data done.')\n",
    "\n",
    "    elif mode == 'processed':\n",
    "        logger.info('-----------------Quick Visualizer Demo of pre-processed data-------------------------')\n",
    "        logger.info(f'Mode for visualization: {mode}')\n",
    "        demo_dataset = DemoDataset(dataset_cfg=dataset_cfg, class_names=class_names, training=True, root_path=data_path, logger=logger, data_processor_flag=True, fov_mode=True)\n",
    "        logger.info(f'Total number of samples: \\t{len(demo_dataset)}')\n",
    "       \n",
    "        data_dict = demo_dataset[0]\n",
    "        print('frame_id: ', data_dict['frame_id'])\n",
    "        points = data_dict['points']\n",
    "        gt_boxes = data_dict['gt_boxes']\n",
    "\n",
    "        Visualizer.draw_demo_scenes(points=points, gt_boxes=gt_boxes, point_colors=None, draw_origin=True)\n",
    "        logger.info('Demo visualization of pre-processed data done.')\n",
    "\n",
    "    elif mode == 'val':\n",
    "        logger.info('-----------------Quick Visualizer Demo of validation .pkl data-------------------------')\n",
    "        logger.info(f'Mode for visualization: {mode}')\n",
    "        pkl_path = ROOT_DIR / 'data' / 'kitti' / 'data_test_pipeline' / 'visualizer' / 'kitti_val_dataset.pkl'\n",
    "\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            demo_val_dataset = pickle.load(f)\n",
    "\n",
    "        data_dict = demo_val_dataset[0]\n",
    "        points = data_dict['points']\n",
    "        gt_boxes_lidar = data_dict['annos']['gt_boxes_lidar']\n",
    "        #lidar_idx = data_dict['point_cloud']['lidar_idx']\n",
    "\n",
    "        #class_n = data_dict['annos']['name']\n",
    "        #print(f\"\\nLidar IDX: {lidar_idx}\")\n",
    "        #print(f\"Points: {points}\\n\")\n",
    "        #print(f\"Class Names: {class_n}\\n\")\n",
    "        #print(f\"Ground Truth Boxes (LiDAR): {gt_boxes_lidar}\")\n",
    "\n",
    "        Visualizer.draw_demo_scenes(points=points, gt_boxes=gt_boxes_lidar, point_colors=None, draw_origin=True, vc='val')\n",
    "        logger.info('Demo visualization of pre-processed validation data done.')\n",
    "\n",
    "    elif mode == 'train':\n",
    "        logger.info('-----------------Quick Visualizer Demo of training .pkl data-------------------------')\n",
    "        logger.info(f'Mode for visualization: {mode}')\n",
    "        #pkl_path = ROOT_DIR / 'data' / 'kitti' / 'data_test_pipeline' / 'visualizer' / 'kitti_train_dataset.pkl'\n",
    "        pkl_path = ROOT_DIR / 'data' / 'kitti' / 'kitti_train_dataset.pkl'\n",
    "    \n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            demo_train_dataset = pickle.load(f)\n",
    "\n",
    "        data_list = demo_train_dataset[0] # specific sample from row no. in train.txt, e.g. (34-1) - 000067)\n",
    "        # [0] - original; [1] - gt_sampling; [2] - flip_x; [3] - w_rotation; [4] - l_rotation\n",
    "\n",
    "        try:\n",
    "            print(\"\\nPlease select an option for the visualization:\")\n",
    "            print('[0] Original')\n",
    "            print('[1] Ground Truth Sampling (gt_sampling)')\n",
    "            print('[2] Flip along X-axis (flip_x)')\n",
    "            print('[3] World rotation (w_rotation)')\n",
    "            print('[4] Local rotation (l_rotation)\\n')\n",
    "            user_choice = int(input('Your selection: '))\n",
    "            if user_choice not in range(5):\n",
    "                raise ValueError('Invalid selection')\n",
    "        except ValueError as e:\n",
    "            print(f\"Error: {e}. Please enter a number between 0 and 4.\")\n",
    "            logger.error(\"Invalid user input for the visualization mode.\")\n",
    "            return\n",
    "        \n",
    "        switch_cases = {0: \"original\", 1: \"gt_sampling\", 2: \"flip_x\", 3: \"w_rotation\", 4: \"l_rotation\"}\n",
    "        \n",
    "        selected_data = data_list[user_choice]\n",
    "        points = selected_data['points']\n",
    "        gt_boxes = selected_data['gt_boxes']\n",
    "\n",
    "        if user_choice in [3, 4]: \n",
    "            noise_key = 'noise_glob_rot' if user_choice == 3 else 'noise_loc_rot'\n",
    "            noise_rot = selected_data.get(noise_key, None)\n",
    "            if noise_rot is not None:\n",
    "                logger.info(f'Noise rotation for {switch_cases[user_choice]}: {noise_rot}')\n",
    "\n",
    "        Visualizer.draw_demo_scenes(points=points, gt_boxes=gt_boxes, point_colors=None, draw_origin=True)\n",
    "        logger.info('Demo visualization of training data done.')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #main(mode='raw')\n",
    "    #main(mode='processed')\n",
    "    #main(mode='val')\n",
    "    main(mode='train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d\n",
    "import numpy as np\n",
    "\n",
    "def text_3d(text, pos, direction=None, degree=0.0, density=10, font='/usr/share/fonts/truetype/freefont/FreeMono.ttf', font_size=10):\n",
    "    if direction is None:\n",
    "        direction = (0., 0., 1.) # default positioned to z-axis\n",
    "\n",
    "    from PIL import Image, ImageFont, ImageDraw\n",
    "    from pyquaternion import Quaternion\n",
    "   \n",
    "\n",
    "    # Adjust font size based on density\n",
    "    font_obj = ImageFont.truetype(font, font_size * density)\n",
    "    #font_obj = ImageFont.truetype(font, font_size)\n",
    "    left, top, right, bottom = font_obj.getbbox(text)\n",
    "    width = right - left\n",
    "    height = bottom - top\n",
    "    font_dim = (width, height)\n",
    "    \n",
    "\n",
    "    # Create an image with the text\n",
    "    img = Image.new('RGB', font_dim, color=(255, 255, 255))\n",
    "    draw = ImageDraw.Draw(img) # white background image\n",
    "    draw.text((-35, -35), text, font=font_obj, fill=(0, 0, 0)) # black\n",
    "    img = np.asarray(img)\n",
    "\n",
    "    # Create a mask for the text pixels\n",
    "    img_mask = img[:, :, 0] < 128\n",
    "    indices = np.indices([*img.shape[0:2], 1])[:, img_mask, 0].reshape(3, -1).T\n",
    "\n",
    "    # Create a point cloud and adjust point density\n",
    "    pcd = open3d.geometry.PointCloud()\n",
    "    pcd.colors = open3d.utility.Vector3dVector(img[img_mask, :].astype(float) / 255.0)\n",
    "    pcd.points = open3d.utility.Vector3dVector(indices / (1000 * density))\n",
    "\n",
    "    # Rotate and translate the point cloud\n",
    "    raxis = np.cross([0.0, 0.0, 1.0], direction)\n",
    "    if np.linalg.norm(raxis) < 1e-6:\n",
    "        raxis = (0.0, 0.0, 1.0)\n",
    "    trans = (Quaternion(axis=raxis, radians=np.arccos(direction[2])) *\n",
    "             Quaternion(axis=direction, degrees=degree)).transformation_matrix\n",
    "    trans[0:3, 3] = np.asarray(pos)\n",
    "    pcd.transform(trans)\n",
    "\n",
    "    return pcd\n",
    "\n",
    "rh_system = open3d.geometry.TriangleMesh.create_coordinate_frame(size=0.02, origin=[0, 0, 0])\n",
    "pcd_10 = text_3d('1 - Car', pos=[0, 0, 0.02], font_size=10, density=5)\n",
    "#open3d.visualization.draw_geometries([pcd_10, chessboard_coord])\n",
    "vis = open3d.visualization.Visualizer()\n",
    "vis.create_window(width=640, height=480)\n",
    "vis.add_geometry(pcd_10)\n",
    "vis.add_geometry(rh_system)\n",
    "vis.run()\n",
    "vis.destroy_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "\n",
    "def create_text_points(text=\"0\", scale=0.1, density=800):  # Sehr hohe Punktdichte für eine durchgehende Linie\n",
    "    \"\"\"\n",
    "    Erstellt eine Punktwolke in Form eines Texts\n",
    "    \"\"\"\n",
    "    if text == \"0\":\n",
    "        # Eine einzelne, sehr dichte Punktreihe für die \"0\"\n",
    "        t = np.linspace(0, 2*np.pi, density)\n",
    "        # Schmaler und höher für einen \"I\"-ähnlichen Look\n",
    "        x = 0.25 * np.cos(t) * scale  # Reduzierte Breite\n",
    "        y = np.sin(t) * scale  # Normale Höhe\n",
    "        z = np.zeros_like(t)\n",
    "        points = np.column_stack((x, y, z))\n",
    "    else:\n",
    "        points = np.array([[0, 0, 0]])\n",
    "    \n",
    "    return points\n",
    "\n",
    "def visualize_bbox_with_label():\n",
    "    vis = o3d.visualization.Visualizer()\n",
    "    vis.create_window(width=960, height=540)\n",
    "    \n",
    "    \n",
    "    bbox = o3d.geometry.OrientedBoundingBox(\n",
    "        center=[0, 0, 0],\n",
    "        R=np.eye(3),\n",
    "        extent=[1, 1, 1]\n",
    "    )\n",
    "    bbox.color = [1, 0, 0]\n",
    "    vis.add_geometry(bbox)\n",
    "    \n",
    "    points = np.random.rand(1000, 3) * 0.8\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(points)\n",
    "    pcd.paint_uniform_color([0, 0.7, 0])\n",
    "    vis.add_geometry(pcd)\n",
    "    \n",
    "    label_position = bbox.get_center() + bbox.extent/2 * np.array([-1, 1, 1])\n",
    "    text_points = create_text_points(scale=0.1) + label_position + np.array([0.1, 0, 0])\n",
    "    \n",
    "    label_pcd = o3d.geometry.PointCloud()\n",
    "    label_pcd.points = o3d.utility.Vector3dVector(text_points)\n",
    "    label_pcd.paint_uniform_color([1, 1, 1])\n",
    "    \n",
    "    # Minimale Tiefe für kaum sichtbaren 3D-Effekt\n",
    "    depth = 0.005  # Stark reduzierte Tiefe\n",
    "    \n",
    "    # Minimale Zwischenpunkte\n",
    "    steps = 2\n",
    "    line_points = []\n",
    "    line_indices = []\n",
    "    \n",
    "    for i, point in enumerate(text_points):\n",
    "        for step in range(steps):\n",
    "            depth_step = depth * (step / (steps - 1))\n",
    "            current_point = point + np.array([0, 0, -depth_step])\n",
    "            line_points.append(current_point)\n",
    "            if step > 0:\n",
    "                line_indices.append([i*steps + step - 1, i*steps + step])\n",
    "    \n",
    "    lines = o3d.geometry.LineSet()\n",
    "    lines.points = o3d.utility.Vector3dVector(line_points)\n",
    "    lines.lines = o3d.utility.Vector2iVector(line_indices)\n",
    "    lines.paint_uniform_color([1, 1, 1])\n",
    "    \n",
    "    vis.add_geometry(label_pcd)\n",
    "    vis.add_geometry(lines)\n",
    "    \n",
    "    opt = vis.get_render_option()\n",
    "    opt.background_color = np.asarray([0.5, 0.5, 0.5])\n",
    "    opt.point_size = 1.0  # Sehr kleine Punktgröße für eine feine Linie\n",
    "    \n",
    "    vis.run()\n",
    "    vis.destroy_window()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    visualize_bbox_with_label()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d\n",
    "import numpy as np\n",
    "import open3d.visualization\n",
    "\n",
    "# Beispiel-Punktwolke erstellen\n",
    "points = np.random.rand(1000, 3)  # Zufällige Punkte für die Demonstration\n",
    "point_cloud = open3d.geometry.PointCloud()\n",
    "point_cloud.points = open3d.utility.Vector3dVector(points)\n",
    "\n",
    "# Erstellen einer Bounding Box für den Punktwolkenbereich\n",
    "bounding_box = open3d.geometry.OrientedBoundingBox.create_from_points(point_cloud.points)\n",
    "bounding_box.color = (1, 0, 0)  # Farbe der Box setzen\n",
    "\n",
    "# Visualisierung mit O3DVisualizer, wie in einem Jupyter Notebook\n",
    "app = open3d.visualization.gui.Application.instance\n",
    "app.initialize()\n",
    "vis = open3d.visualization.O3DVisualizer(\"Open3D - 3D Text\", 1024, 768)\n",
    "vis.show_settings = True\n",
    "vis.add_geometry(\"Points\", point_cloud)\n",
    "vis.add_geometry(\"Bounding Box\", bounding_box)\n",
    "vis.show()\n",
    "#app.add_window()\n",
    "#app.run()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openpcdet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
